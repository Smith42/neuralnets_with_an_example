{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural nets with a practical example\n",
    "\n",
    "#### Mike Smith (University of Hertfordshire) -- 2020-09\n",
    "\n",
    "We're going to diagnose myocardial infarctions (heart attacks) using a feedforward neural network written in pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the ECG dataset\n",
    "\n",
    "You can find it nicely packaged here: \n",
    "    \n",
    "  https://www.kaggle.com/openmark/ptb-diagnostic-ecg-database\n",
    "\n",
    "or in its original form here:\n",
    "    \n",
    "  https://www.physionet.org/content/ptbdb/1.0.0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecgs = np.load(\"data/data_raw.npz\")\n",
    "meta = pd.read_csv(\"data/meta.csv\", quotechar='\"', delimiter=\",\")\n",
    "meta.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where are these leads from?\n",
    "\n",
    "[![limb leads](figs/limb_leads.png)](https://commons.wikimedia.org/wiki/File:Limb_leads_of_EKG.png)\n",
    "[![v1-6](figs/v1-6.png)](https://en.wikipedia.org/wiki/File:Precordial_leads_in_ECG.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A typical ECG's anatomy\n",
    "\n",
    "[![ecg](./figs/ecg.png)](https://en.wikipedia.org/wiki/File:SinusRhythmLabels.svg)\n",
    "\n",
    "[![ecggif](./figs/ecg.gif)](https://commons.wikimedia.org/wiki/File:ECG_principle_slow.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1, 12, figsize=(18, 2))\n",
    "for i, ax, lead in zip(range(12), axs.ravel(), [\"I\", \"II\", \"III\", \"aVR\", \"aVL\", \"aVF\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\"]):\n",
    "    ax.set_title(lead)\n",
    "    ax.axis(\"off\")\n",
    "    ax.plot(ecgs[\"patient212/s0434_re\"][400:1100, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does the dataset look like?:\n",
    "\n",
    "We're going to look for patient's with a myocardial infarction (which typically induces ST-elevation).\n",
    "\n",
    "[![st-elev](./figs/ecg_stelevation_mi.jpg)](https://commons.wikimedia.org/wiki/File:12_Lead_EKG_ST_Elevation_tracing_color_coded.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses = meta[[\"patient\", \"record_id\", \"Reason_for_admission\"]]\n",
    "healthies = diagnoses[(diagnoses[\"Reason_for_admission\"] == \"Healthy control\")]\n",
    "ills = diagnoses[(diagnoses[\"Reason_for_admission\"] == \"Myocardial infarction\")]\n",
    "print(\"We have {} ill patients and {} healthy patients!\".format(len(set(ills[\"patient\"])), len(set(healthies[\"patient\"]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's split the patients into training and test sets (+ populate those sets with individual scans):\n",
    "\n",
    "We want to balance the training and testing sets so that they contain roughly similar amounts of ECG scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_patients = (list(set(healthies[\"patient\"]))[40:52], list(set(ills[\"patient\"]))[120:148])\n",
    "training_patients = (list(set(healthies[\"patient\"]))[:40], list(set(ills[\"patient\"]))[:120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want mitigate ECG \"walk\" where the ECG signal moves from a level signal.\n",
    "# We can do this by taking the differential of the ECG signal.\n",
    "# If we then take the absolute value of this we can easily detect the QRS complexes using scipy.signal.find_peaks.\n",
    "\n",
    "# Once we get the locations of the QRS complexes we can crop out a full ECG scan, and populate a numpy array with them.\n",
    "f, axs = plt.subplots(2, 1)\n",
    "axs[0].plot(ecgs[\"patient212/s0434_re\"][:4000, 0])\n",
    "axs[1].plot(np.abs(np.diff(ecgs[\"patient212/s0434_re\"][:4000, 0])))\n",
    "\n",
    "# Find peaks:\n",
    "peaks, _ = find_peaks(np.abs(np.diff(ecgs[\"patient212/s0434_re\"][:4000, 0])), distance=500)\n",
    "[axs[0].axvline(peak, 0, 0.25, color=\"r\") for peak in peaks]\n",
    "[axs[1].axvline(peak, 0, 0.25, color=\"r\") for peak in peaks]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_array(patients):\n",
    "    \"\"\"\n",
    "    Populate an array of ECG scans given a list of patients.\n",
    "    \"\"\"\n",
    "    scans = []\n",
    "    for name in tqdm.tqdm(ecgs.files):\n",
    "        if name.split(\"/\")[0] in patients:\n",
    "            qrss, _ = find_peaks(np.abs(np.diff(ecgs[name][:, 0])), distance=500)\n",
    "            raw_ecgs = ecgs[name]\n",
    "            for qrs in qrss:\n",
    "                if raw_ecgs[qrs - 300:qrs + 300, :12].shape == (600, 12):\n",
    "                    scans.append(raw_ecgs[qrs - 300:qrs + 300, :12])\n",
    "            del raw_ecgs # we need to do this to stop a memory leak...\n",
    "                \n",
    "    return np.array(scans)\n",
    "\n",
    "# Generate training set\n",
    "training_set = (populate_array(training_patients[0]), populate_array(training_patients[1]))\n",
    "# Balance training set\n",
    "smallest_set = np.min((len(training_set[0]), len(training_set[1])))\n",
    "print(smallest_set, \"(x2) in the training set\")\n",
    "training_set = np.concatenate((training_set[0][:smallest_set], training_set[1][:smallest_set]), axis=0)\n",
    "training_labels = np.concatenate((np.zeros(smallest_set), np.ones(smallest_set)), axis=0)\n",
    "\n",
    "# Generate testing set\n",
    "testing_set = (populate_array(testing_patients[0]), populate_array(testing_patients[1]))\n",
    "# Balance testing set\n",
    "smallest_set = np.min((len(testing_set[0]), len(testing_set[1])))\n",
    "print(smallest_set, \"(x2) in the testing set\")\n",
    "testing_set = np.concatenate((testing_set[0][:smallest_set], testing_set[1][:smallest_set]), axis=0)\n",
    "testing_labels = np.concatenate((np.zeros(smallest_set), np.ones(smallest_set)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise training and test sets\n",
    "def min_max_norm(ar):\n",
    "    return (ar - ar.min())/(ar.max() - ar.min())\n",
    "\n",
    "training_set = [min_max_norm(ecg) for ecg in training_set]\n",
    "testing_set = [min_max_norm(ecg) for ecg in testing_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(6, 12, figsize=(18, 12))\n",
    "for i in range(6):\n",
    "    rand_choice = np.random.randint(0, len(training_set))\n",
    "    ecg = training_set[rand_choice]\n",
    "    label = training_labels[rand_choice]\n",
    "    for j, ax, lead in zip(range(12), axs[i].ravel(), [\"I\", \"II\", \"III\", \"aVR\", \"aVL\", \"aVF\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\"]):\n",
    "        axs[i, j].set_title((int(label), lead))\n",
    "        ax.axis(\"off\")\n",
    "        ax.plot(ecg[:, j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we have the training and testing sets, let's start writing the ANN\n",
    "\n",
    "We'll use a modified version of Lecun's LeNet-5, developed in the late 80s for OCR (some papers using the model are found [here](http://yann.lecun.com/exdb/lenet/)).\n",
    "\n",
    "![lenet-5](figs/lenet-5.png)\n",
    "\n",
    "Figure from [\"Gradient-Based Learning Applied to Document Recognition\", Y. LeCun et al. 1998](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf).\n",
    "\n",
    "## What is a fully connected layer?\n",
    "\n",
    "A layer made up of many artificial neurons:\n",
    "\n",
    "<img src=\"figs/AN.png\" width=400>\n",
    "\n",
    "Example of a fully connected neural network binary classifier:\n",
    "\n",
    "<img src=\"figs/ANN.png\" width=600>\n",
    "\n",
    "## What's a convolution?\n",
    "\n",
    "[![conv](figs/conv.gif)](http://ufldl.stanford.edu/tutorial/supervised/FeatureExtractionUsingConvolution/)\n",
    "\n",
    "## Grad descent\n",
    "\n",
    "[![gdesc](figs/gradient_descent.gif)](http://vis.supstat.com/2013/03/gradient-descent-algorithm-with-r/)\n",
    "\n",
    "We'll write the network in PyTorch because it's nice to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our ECGNet will be the same as LeCun's LeNet 5 (with 1D CNNs in place of 2D CNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EcgNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(EcgNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(12, 16, 3)\n",
    "        self.conv2 = nn.Conv1d(16, 32, 3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(32 * 148, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # a 1D max pool over the length of the ECG\n",
    "        x = F.max_pool1d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool1d(F.relu(self.conv2(x)), 2)\n",
    "        # Reshape ready for input into FC layer\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "ecgnet = EcgNet()\n",
    "print(ecgnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define an accuracy metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(ys, ps):\n",
    "    acc = (torch.round(ys) == torch.round(ps)).float().detach().numpy()\n",
    "    return float(acc.sum()/len(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the optimiser + criterion (loss). We'll use [Adam](https://arxiv.org/abs/1412.6980) and [Binary Cross Entropy](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optim.Adam(ecgnet.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some init stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 6\n",
    "batch_size = 16\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(training_set, training_labels, test_size=0.20)\n",
    "\n",
    "losses = []\n",
    "accs = []\n",
    "global_vlosses = []\n",
    "global_vaccs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(epoch, \"/\", epochs - 1)\n",
    "    # Shuffle the training set before each epoch\n",
    "    x_train, y_train = shuffle(x_train, y_train)\n",
    "    \n",
    "    t = tqdm.trange(0, len(x_train), batch_size) # This gives us a nice progress bar\n",
    "    \n",
    "    for step in t:\n",
    "        optimiser.zero_grad() # Remove all gradients before training\n",
    "        \n",
    "        # Get a single batch and populate ys, xs, ps:\n",
    "        ys = y_train[step:step + batch_size]\n",
    "        ys = torch.from_numpy(np.array(ys)[..., np.newaxis]).float()\n",
    "        xs = x_train[step:step + batch_size]\n",
    "        xs = torch.from_numpy(np.array(xs).swapaxes(1, 2))\n",
    "        ps = ecgnet(xs)\n",
    "        \n",
    "        # Get the loss\n",
    "        loss = criterion(ps, ys)\n",
    "        # Get the accuracy for us (NN doesn't use this here)\n",
    "        acc = accuracy(ps, ys)\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        accs.append(acc)\n",
    "        t.set_description(\"{:.04f}, {:.04f}\".format(loss.item(), acc))\n",
    "        \n",
    "        # Backpropagate the loss through the network and update the weights to follow the loss down\n",
    "        loss.backward()\n",
    "        # Update the optimiser\n",
    "        optimiser.step()\n",
    "        \n",
    "    # Validate after each epoch\n",
    "    vlosses = []\n",
    "    vaccs = []\n",
    "    t = tqdm.trange(0, len(x_valid), batch_size)\n",
    "    for step in t:\n",
    "        # Same as before, but sampling batches thru the validation set\n",
    "        ys = y_valid[step:step + batch_size]\n",
    "        ys = torch.from_numpy(np.array(ys)[..., np.newaxis]).float()\n",
    "        xs = x_valid[step:step + batch_size]\n",
    "        xs = torch.from_numpy(np.array(xs).swapaxes(1, 2))\n",
    "        ps = ecgnet(xs)\n",
    "\n",
    "        vlosses.append(criterion(ps, ys).item())\n",
    "        vaccs.append(accuracy(ps, ys))\n",
    "\n",
    "    # Here are our valid set metrics\n",
    "    print(\"Validation set loss and accuracy:\")\n",
    "    print(\"Loss {:.04f} Acc {:.04f}\".format(np.mean(vlosses, axis=0), np.mean(vaccs, axis=0)))\n",
    "    global_vlosses.append(np.mean(vlosses, axis=0))\n",
    "    global_vaccs.append(np.mean(vaccs, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to see if our model improves in both the training and validation sets.\n",
    "\n",
    "So let's plot a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get total number of global steps\n",
    "global_steps = (len(x_train)//batch_size) * epochs\n",
    "\n",
    "# Plot stuff\n",
    "f, axs = plt.subplots(2, 1, sharex=True)\n",
    "axs[0].plot(range(global_steps)[::50], \n",
    "         losses[::50], \n",
    "         \"r\", label=\"Training loss\")\n",
    "axs[0].plot(np.arange(1, epochs + 1) * len(x_train)//batch_size, \n",
    "         global_vlosses, \n",
    "         \"o\", color=\"olive\", label=\"Validation loss\")\n",
    "axs[0].set_ylabel(\"BXE loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(range(global_steps)[::50], \n",
    "         accs[::50], \n",
    "         \"b\", label=\"Training accuracy\")\n",
    "axs[1].plot(np.arange(1, epochs + 1) * len(x_train)//batch_size, \n",
    "         global_vaccs, \n",
    "         \"o\", color=\"cyan\", label=\"Validation accuracy\")\n",
    "axs[1].set_ylabel(\"Accuracy as a fraction\")\n",
    "axs[1].legend()\n",
    "\n",
    "f.suptitle(\"Metrics for ECGNet\")\n",
    "axs[1].set_xlabel(\"Global step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great!! (or is it?) Let's check the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taccs = []\n",
    "\n",
    "x_test, y_test = shuffle(testing_set, testing_labels)\n",
    "\n",
    "t = tqdm.trange(0, len(x_test), batch_size)\n",
    "for step in t:\n",
    "    ys = y_test[step:step + batch_size]\n",
    "    ys = torch.from_numpy(np.array(ys)[..., np.newaxis]).float()\n",
    "    xs = x_test[step:step + batch_size]\n",
    "    xs = torch.from_numpy(np.array(xs).swapaxes(1, 2))\n",
    "    ps = ecgnet(xs)\n",
    "    taccs.append(accuracy(ps, ys))\n",
    "\n",
    "print(\"Test set accuracy:\")\n",
    "print(\"Acc {:.04f}\".format(np.mean(taccs, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_steps = (len(x_train)//batch_size) * 6\n",
    "f, axs = plt.subplots(1, 1, sharex=True)\n",
    "axs.plot(range(global_steps)[::50], \n",
    "         accs[::50], \n",
    "         \"b\", label=\"Training accuracy\")\n",
    "axs.plot(np.arange(1, epochs + 1) * len(x_train)//batch_size, \n",
    "         global_vaccs, \n",
    "         \"o\", color=\"cyan\", label=\"Validation accuracy\")\n",
    "axs.axhline(np.mean(taccs, axis=0), linestyle=\"--\", label=\"Test set loss\")\n",
    "axs.set_ylabel(\"Accuracy as a fraction\")\n",
    "axs.legend()\n",
    "\n",
    "axs.set_title(\"Metrics for ECGNet\")\n",
    "axs.set_xlabel(\"Global step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not perfect, what else can we do?\n",
    "\n",
    "# Other things we could try:\n",
    "\n",
    "* Regularisation to reduce overfitting\n",
    "* Other neural network architectures (i.e. ResNet, RevNet, RNN, ...)\n",
    "* More data/more involved data preprocessing\n",
    "* Change the data shape (i.e. a 2D CNN across all 12 channels?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
